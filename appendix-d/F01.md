---
title: "F01. AI Evolution Ladder"
nav_order: 4
parent: 부록 D
---

OpenAI는 AI 발전을 5단계로 나눕니다. 챗봇에서 시작해 추론하는 AI, 행동하는 에이전트, 혁신하는 AI, 조직을 운영하는 AI까지. Anthropic도 비슷하게 에이전트의 자율성을 0부터 4까지 레벨로 구분합니다. 수동적인 도구에서 시작해 도구를 호출하고, 생각과 행동을 반복하고, 상태를 기억하고, 결국 스스로 작동을 시작하는 자율 에이전트까지.

이 프레임워크들은 유용합니다. 하지만 비전공자 친화적인 프레임워크가 지형도를 조망하기 위해 필요하다고 생각했습니다. 그래서 AI Evolution Ladder, AI 진화 사다리라는 개념을 제안합니다. 컴퓨터의 등장부터 멀티에이전트 시스템과 AGI까지 80년 역사와 가까운 미래를 글 하나로 압축했습니다. 최신 기술은 조금 더 잘게 구분했습니다.

![image.png](attachment:a5f644c5-db11-4060-bdeb-5190edac9a2e:image.png)

이 책은 SW부터 MAS까지를 다룹니다.

`HW → SW → Web → Mobile → AI → LLM → Tool-use → Agent → A2A → MAS → (AGI)`

| # | 이름 | 핵심 | 예시 | 시대 |
| --- | --- | --- | --- | --- |
| 1 | HW | 계산의 물리적 구현 | 진공관, 트랜지스터, CPU | 1940s~ |
| 2 | SW | 규칙 기반 실행 | UNIX, Windows, Excel | 1960s~ |
| 3 | Web | 연결과 접근성 | 브라우저, SaaS, 클라우드 | 1990s~ |
| 4 | Mobile | 상시 접속과 앱 생태계 | iPhone, 앱스토어, 카카오톡 | 2007~ |
| 5 | AI | 데이터에서 패턴 학습 | 이미지 분류, 추천 알고리즘 | 2012~ |
| 6 | LLM | 언어라는 범용 인터페이스 | GPT, Claude | 2022~ |
| 7 | Tool-use | 외부 도구 호출과 실행 | RAG, Function Calling | 2023~ |
| 8 | Agent | 목표 기반 자율 행동 | Claude Code, Cursor | 2024~ |
| 9 | A2A | 에이전트 간 통신과 위임 | MCP, Google A2A | 2025~ |
| 10 | MAS | 에이전트 조직과 협업 | CrewAI, AutoGen | 2025~ |
| 11 | AGI | 범용 인공지능 | (아직 없음) | ? |

각 단계별 설명:

- 하드웨어 = 계산의 물리적 구현: 인간은 계속해서 도구를 만들어왔습니다. 불을 다루고, 바퀴를 굴리고, 증기기관을 돌렸습니다. 그러다 전기를 발견했습니다. 전기는 켜고 끄는 두 가지 상태를 만들 수 있었고, 이것이 0과 1이 됐습니다. 1940년대, 이 원리로 진공관을 만들었습니다. 진공관 18,000개를 연결하면 방 하나를 가득 채우는 ENIAC이 됐습니다. 최초의 범용 컴퓨터였습니다. 1초에 5,000번 덧셈을 할 수 있었죠. 하지만 진공관은 뜨겁고 크고 잘 고장났습니다. 1950년대, 같은 기능을 손톱만 한 크기로 압축한 트랜지스터가 등장했습니다. 트랜지스터 수천 개를 하나의 칩에 새기는 집적회로가 나왔고, 1970년대에 인텔 4004 마이크로프로세서가 탄생했습니다. 컴퓨터가 방에서 책상 위로 내려왔습니다. IBM PC, 애플 매킨토시. 개인이 컴퓨터를 소유하는 시대가 열렸습니다.

- 소프트웨어 = 규칙 기반 실행: 컴퓨터는 있는데, 어떻게 명령을 내릴까요. 초기에는 기계어로 직접 0과 1을 입력해야 했습니다. 너무 어려웠습니다. 1950년대, 사람이 읽을 수 있는 프로그래밍 언어가 등장했습니다. FORTRAN, COBOL. "ADD A TO B"라고 쓰면 컴퓨터가 알아서 기계어로 번역했죠. 1960년대에는 운영체제가 나왔습니다. 여러 프로그램을 동시에 돌리고, 파일을 관리하고, 사용자와 소통하는 중간 관리자입니다. UNIX가 대학에서 퍼졌고, MS-DOS가 PC에 깔렸고, Windows가 마우스와 아이콘을 가져왔습니다. 이제 누구나 클릭 몇 번으로 워드프로세서를 열고, 스프레드시트에 숫자를 넣을 수 있었습니다. Excel에서 "=A1+B1"이라고 쓰면 두 셀의 값을 더합니다. 사람이 규칙을 정의하고, 컴퓨터가 그 규칙을 정확히 따릅니다.

- 웹 = 연결과 접근성: 컴퓨터가 혼자 있으면 섬입니다. 1969년, 미국 국방부가 ARPANET을 만들었습니다. 컴퓨터 4대를 연결한 게 시작이었습니다. 1990년, 팀 버너스리가 유럽입자물리연구소(CERN)에서 월드 와이드 웹을 발명했습니다. 문서를 링크로 연결하는 아이디어였죠. 1993년, 모자이크 브라우저가 나왔습니다. 이미지와 텍스트를 함께 볼 수 있었습니다. 인터넷이 대중에게 열렸습니다. 닷컴 버블이 일었습니다. 아마존, 이베이, 야후. 2000년대에 버블이 꺼졌지만, 인터넷은 남았습니다. 웹 2.0이 왔습니다. 사용자가 직접 콘텐츠를 만들기 시작했습니다. 블로그, 위키피디아, 유튜브, 페이스북. 2006년, 아마존이 AWS를 시작했습니다. 서버를 사지 않고 빌려 쓰는 클라우드의 시대. 소프트웨어를 설치하지 않고 브라우저에서 쓰는 SaaS의 시대가 열렸습니다.

- 모바일 = 상시 접속과 앱 생태계: 2007년 1월, 스티브 잡스가 무대에 섰습니다. "오늘 세 가지 제품을 소개합니다. 터치스크린 아이팟, 혁신적인 휴대폰, 인터넷 커뮤니케이터." 청중이 환호했습니다. 잡스가 말했습니다. "이건 세 개가 아닙니다. 하나입니다." 아이폰이었습니다. 손가락으로 화면을 쓸고, 확대하고, 누르는 인터페이스. 2008년에 앱스토어가 열렸습니다. 누구나 앱을 만들어 올릴 수 있었습니다. 스마트폰이 폭발했습니다. 카카오톡이 문자를 대체했습니다. 인스타그램이 사진을 바꿨습니다. 우버가 택시를 부르는 방식을 바꿨습니다. 배달의민족이 음식 주문을 바꿨습니다. GPS로 위치를 알고, 카메라로 세상을 찍고, 마이크로 음성을 듣습니다. 컴퓨터가 주머니 속으로 들어갔습니다. 사람들은 하루에 수십 번, 수백 번 화면을 켭니다.

- 인공지능 = 데이터에서 패턴 학습: 소프트웨어는 사람이 짠 규칙을 따랐습니다. "만약 A이면 B를 해라." 모든 경우의 수를 프로그래머가 미리 정의해야 했습니다. 그런데 고양이 사진을 인식하려면 어떤 규칙을 짜야 할까요? "귀가 뾰족하면 고양이"? 누워있는 고양이는? 뒤돌아 있는 고양이는? 규칙으로는 한계가 있었습니다. 2012년, 알렉스넷이 이미지넷 대회에서 압도적으로 우승했습니다. 규칙을 짜는 대신, 고양이 사진 수백만 장을 보여주고 "이게 고양이야"라고 가르쳤습니다. 컴퓨터가 스스로 고양이의 특징을 찾아냈습니다. 딥러닝이었습니다. 신경망이 깊어지고, GPU가 계산을 가속하고, 데이터가 쏟아졌습니다. 이미지 인식, 음성 인식, 번역, 추천 알고리즘. 넷플릭스가 당신이 좋아할 영화를 알고, 스포티파이가 당신의 취향을 파악합니다.

- LLM = 언어라는 범용 인터페이스: 2017년, 구글이 "Attention Is All You Need"라는 논문을 발표했습니다. 트랜스포머 아키텍처입니다. 문장에서 어떤 단어가 어떤 단어와 연결되는지 한 번에 파악하는 방식이죠. 2018년, OpenAI가 GPT-1을 발표했습니다. 인터넷의 텍스트를 읽고 "다음 단어 예측"이라는 단순한 과제를 수행하도록 훈련했습니다. GPT-2, GPT-3, GPT-4. 모델이 커지고, 데이터가 많아지고, 컴퓨팅이 강해질수록 능력이 폭발했습니다. 번역도 하고, 요약도 하고, 코드도 씁니다. 이전까지 AI는 특정 태스크를 위해 별도로 훈련됐습니다. 번역 모델, 요약 모델, 질문응답 모델이 따로 있었습니다. LLM은 달랐습니다. 하나의 모델이 수백 가지 일을 합니다. 2022년 11월, ChatGPT가 공개됐습니다. 두 달 만에 1억 명이 사용했습니다.

- Tool-Use = 외부 도구 호출과 실행: LLM은 공개된 웹과 모바일을 대부분 학습해서 세상 지식을 알지만, 오늘 날씨는 모릅니다. 학습 데이터에 없으니까요. 계산도 자주 틀립니다. 9.11과 9.8 중 뭐가 큰지 헷갈립니다. 2023년, OpenAI가 ChatGPT에 플러그인을 붙였습니다. 검색 엔진을 연결하면 최신 정보를 찾을 수 있습니다. Code Interpreter를 붙이면 파이썬 코드를 직접 실행할 수 있습니다. 계산기 대신 코드를 돌리니까 틀릴 일이 없죠. Anthropic은 MCP(Model Context Protocol)를 발표했습니다. 데이터베이스, 파일 시스템, API를 LLM에 연결하는 표준입니다. RAG(Retrieval-Augmented Generation)는 회사 내부 문서를 검색해서 답변에 활용합니다. Function Calling은 LLM이 외부 함수를 호출하도록 합니다.

- 에이전트 = 목표 기반 자율 행동: "이 폴더의 코드를 리팩토링해." 이전까지 AI는 이 요청을 받으면 조언을 줬습니다. "먼저 파일 구조를 파악하시고, 중복된 함수를 찾으시고..." 에이전트는 다릅니다. 직접 파일을 열어봅니다. 코드를 분석합니다. 문제를 발견합니다. 수정안을 만듭니다. 코드를 고칩니다. 테스트를 돌립니다. 실패하면 다시 고칩니다. 성공하면 커밋합니다. 한 번의 지시로 수십 번의 행동이 이어집니다. Claude Code는 터미널에서 동작하는 코딩 에이전트입니다. 파일을 읽고, 쓰고, 명령어를 실행합니다. 핵심은 "생각→행동→관찰" 루프입니다. 상황을 보고, 무엇을 할지 판단하고, 실행하고, 결과를 관찰하고, 다음 행동을 결정합니다. 이걸 ReAct 패턴이라고 부릅니다.

- A2A = 에이전트 간 통신과 위임: 에이전트가 혼자서 모든 일을 하려면 한계가 있습니다. 코딩도 잘하고, 테스트도 잘하고, 문서화도 잘하고, 디자인도 잘하는 에이전트? 쉽지 않습니다. 사람도 그렇습니다. 그래서 팀을 이룹니다. 에이전트도 마찬가지입니다. 코딩 에이전트가 있고, 테스트 에이전트가 있고, 문서화 에이전트가 있습니다. 문제는 어떻게 대화하느냐입니다. 2024년, Anthropic이 MCP를 발표했습니다. 에이전트가 외부 도구와 데이터에 접근하는 표준 프로토콜입니다. 2025년, 구글이 A2A(Agent-to-Agent) 프로토콜을 발표했습니다. 에이전트끼리 대화하는 표준이죠. 코딩 에이전트가 코드를 쓰면 테스트 에이전트에게 "이거 테스트해줘"라고 요청합니다. 테스트 에이전트가 결과를 돌려줍니다. 문제가 있으면 코딩 에이전트가 다시 수정합니다.

- MAS = 에이전트 조직과 협업: 1:1 협업을 넘어서, 여러 에이전트가 팀을 이룹니다. PM 에이전트가 요구사항을 정리합니다. 아키텍트 에이전트가 설계를 합니다. 개발자 에이전트가 코드를 씁니다. 테스터 에이전트가 테스트합니다. 리뷰어 에이전트가 코드를 검토합니다. 마치 스타트업 팀처럼 각자의 역할이 있고, 서로 대화하며 하나의 프로젝트를 완성합니다. 아직 초기 단계입니다. 에이전트들이 서로 오해하고, 루프에 빠지고, 비효율적으로 일하기도 합니다. 하지만 방향은 분명합니다. 핵심은 조직 구조의 형성입니다. 단순히 1:1로 대화하는 게 아니라, 여러 에이전트가 역할을 나누고 협업합니다. 인간 조직처럼.

- AGI(범용 인공지능) = a system that really understands everything around you: 다음은 아직 비어있습니다. 범용적인 새로운 사실을 스스로 인간처럼 학습해낼 수 있는 시스템? 상상할 수는 있지만 예상할 수는 없습니다. 무엇과 합쳐져 시너지를 낼지도 모릅니다. 로봇? 단백질접힘? 양자컴퓨팅? 데이터센터? 메모리반도체? 딥마인드의 하사비스 대표와 앤드류 응 박사가 AGI의 정의를 두고 다투는 상황에서 이런 변화가 5년 후에 올지 20년 후에 올지는 모르겠습니다. 하사비스는 AGI가 하나의 모델이 아니라 시스템일 것이라고 말했습니다. 지금 보고 있는 멀티에이전트 시스템이 그 방향의 초기 형태일 수도 있습니다. 확실한 사실은 하나입니다. 지금 이 순간에도 예상할 수 없는 속도로 그 방향으로 나아가고 있다는 것.
