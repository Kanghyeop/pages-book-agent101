---
title: "F03. F03. 에이전트의 학문적 정의와 스펙트럼"
nav_order: 6
parent: 부록 D
---

조금 지루하고 학구적일수도 있지만, 책의 핵심 키워드가 '에이전트'인 만큼, 정의는 짧게 살펴보고 넘어가도록 합시다.

2025년부터 '에이전트'라는 단어가 AI 업계를 휩쓸기 시작했습니다. 수많은 프레임워크와 도구들이 쏟아져 나왔고, 모든 것이 '에이전트'라는 이름을 달았습니다. 그런데 정작 '에이전트가 뭔가요?'라고 물으면, 대답은 제각각입니다. 누군가는 'LLM이 도구를 쓰는 것'이라 하고, 누군가는 '스스로 계획을 세우는 AI'라 합니다. 마케팅 용어와 기술 용어가 뒤섞여 본질은 흐려졌습니다.

이 챕터는 그 본질을 살피는 과정입니다. 먼저 30년 된 학문적 정의(Part 1)를 살펴본 뒤, 오늘날 무엇이 달라졌는지(Part 2)를 다룹니다.

---

# Part 1: 전통적 정의

> 1990년대부터 쌓여온 학문적 정의를 살펴봅니다. 에이전트라는 개념의 뿌리를 이해하면, 오늘날의 혼란스러운 용어들을 더 명확하게 볼 수 있습니다.

---

## 최대정의와 최소정의

### 온도 조절기도 에이전트인가?

AI 고전으로 자리 잡은 『Artificial Intelligence: A Modern Approach』(1995)에서 스튜어트 러셀과 피터 노빅은 에이전트를 이렇게 정의합니다.

> "에이전트란 센서를 통해 환경을 인식하고, 작동기를 통해 그 환경에 행동하는 모든 것이다."
>

![에이전트 기본 구조](/pages-book-agent101/assets/agent-structure.svg)

> **[Note]** 이 다이어그램은 수정이 필요합니다. 에이전트 박스 외부의 곡선이 끊겨 있고, 환경과의 상호작용이 명확하게 표현되지 않았습니다.

이 정의에 따르면, 온도 조절기도 에이전트입니다. 온도를 감지하고(센서), 히터를 켜고 끕니다(작동기). 놀라셨나요? 하지만 러셀과 노빅의 의도는 명확했습니다. 이들은 에이전트라는 개념을 가능한 넓게 정의한 뒤, 거기서 '합리적 에이전트', '지능적 에이전트'로 점점 좁혀가는 방식을 택했습니다.

그런데 온도 조절기와 AlphaGo가 같은 '에이전트'라니, 뭔가 이상하지 않나요? 둘을 가르는 건 대체 무엇일까요?

## 프랭클린과 그래서의 답: 자율성

1996년, 스탠 프랭클린과 아트 그래서는 "이것은 에이전트인가, 아니면 그냥 프로그램인가?"라는 도발적인 제목의 논문을 발표합니다. 이들은 프로그램과 에이전트를 구분하는 핵심 요소로 '자율성'을 제시했습니다.

> "자율 에이전트란 환경 속에 위치하여 그 일부가 되고, 환경을 감지하며, 시간에 걸쳐 자신의 목표(agenda)를 추구하며 행동하는 시스템이다."
>

이 정의의 핵심 요소를 하나씩 살펴봅시다.

**자율 에이전트의 네 가지 요소**
- 환경에 위치함: 진공 속이 아니라 어딘가에 '있다'
- 감지: 환경의 상태를 인지한다
- 시간에 걸쳐: 일회성이 아닌 지속적 존재
- 자신의 목표: 외부가 아닌 스스로의 목표를 가진다

온도 조절기도 이 정의에는 부합합니다. 하지만 '자신의 목표'에서 차이가 드러나기 시작합니다. 온도 조절기의 목표는 설계자가 심어준 것이죠. 반면, 더 발전된 자율 에이전트는 자신의 경험을 통해 목표를 스스로 수정할 수 있습니다.

---

## 지능적 에이전트의 네 가지 조건

프랭클린과 그래서의 정의는 '에이전트란 무엇인가'를 설명해줍니다. 하지만 이 정의대로라면 온도 조절기도 에이전트입니다. 환경에 위치하고, 온도를 감지하고, 계속 작동하며, 설정된 목표를 따르니까요. 그렇다면 온도 조절기와 AlphaGo를 같은 '에이전트'라고 부를 수 있을까요? 뭔가 빠진 것 같습니다.

1995년, 마이클 울드리지와 닉 제닝스는 여기서 한 걸음 더 나아갑니다. 이들은 단순히 "에이전트인가?"가 아니라 "지능적 에이전트인가?"를 묻습니다. 그리고 네 가지 조건을 제시했습니다.

![지능적 에이전트의 4가지 조건](/pages-book-agent101/assets/agent-conditions.svg)

1. 자율성(Autonomy)
인간이 매 단계마다 개입하지 않아도 스스로 동작할 수 있어야 합니다. 버튼을 눌러야만 움직이는 시스템은 자율적이지 않죠. 다만 완전한 자율성까지는 요구하지 않습니다. 인간의 감독 하에 작동하더라도, 세부 단계에서 스스로 결정을 내릴 수 있으면 됩니다.

2. 사회적 능력(Social Ability)
다른 에이전트—인간이든 기계든—와 상호작용할 수 있어야 합니다. 이 점이 '도구'와 '에이전트'를 가릅니다. 망치는 사람이 쥐어야 작동하지만, 에이전트는 다른 존재와 협력하거나 협상합니다.

3. 반응성(Reactivity)
환경의 변화를 감지하고 적절한 시간 내에 대응해야 합니다. 여기서 중요한 건 '적절한 대응'입니다. 단순히 "온도가 낮으면 히터 켜기" 같은 고정된 규칙이 아니라, 예상치 못한 상황에서도 맥락에 맞게 대처할 수 있어야 합니다.

4. 능동성(Proactivity)
반응성이 "환경이 바뀌면 대응한다"라면, 능동성은 "환경이 안 바뀌어도 스스로 행동한다"입니다. 온도 조절기는 온도가 떨어져야 반응하지만, 능동적 에이전트는 '오늘 밤 추워질 것 같으니 미리 히터를 틀어두자'라고 스스로 판단합니다.

---

### 자율 에이전트 vs 지능적 에이전트

두 정의의 차이를 정리하면 이렇습니다.

| | 자율 에이전트 | 지능적 에이전트 |
|---|---|---|
| 핵심 질문 | 스스로 작동하는가? | 똑똑하게 작동하는가? |
| 목표 | 주어진 목표를 따름 | 목표를 스스로 조정함 |
| 상호작용 | 환경과만 상호작용 | 다른 에이전트와도 협력·협상 |
| 대응 방식 | 고정된 규칙 | 맥락에 맞는 유연한 대응 |
| 행동 개시 | 입력이 있어야 반응 | 입력 없이도 먼저 행동 |

온도 조절기는 자율 에이전트의 조건은 충족하지만, 지능적 에이전트의 조건에서는 탈락합니다. 사회적 능력이 없고, 고정된 규칙만 따르며, 스스로 먼저 행동하지 못하니까요.

---

## BDI: 마음을 가진 에이전트

울드리지와 제닝스의 네 가지 조건은 지능적 에이전트가 '무엇을 할 수 있어야 하는지'를 말해줍니다. 하지만 한 가지 질문이 남습니다. 에이전트는 어떻게 그런 행동을 하는 걸까요? 내부에서 무슨 일이 벌어지길래 자율적으로 판단하고, 능동적으로 행동할 수 있는 걸까요?

1980년대 말, 철학자 마이클 브랫먼의 '실용적 추론' 이론이 이 질문에 답을 제시했습니다. 그의 제자들이었던 아난드 라오와 마이클 조지프는 이를 바탕으로 BDI 모델을 만들었습니다.

BDI는 Belief(믿음), Desire(욕구), Intention(의도)의 약자입니다. 이 모델은 에이전트의 '마음 상태'를 세 가지로 분해합니다.

![BDI 모델](/pages-book-agent101/assets/bdi-model.svg)

**1. Belief: 세상에 대한 믿음**
에이전트가 세상에 대해 알고 있다고 '생각하는' 것입니다. 중요한 건 이것이 '지식(knowledge)'이 아니라 '믿음(belief)'이라는 점입니다. 틀릴 수 있고, 불완전할 수 있고, 나중에 바뀔 수 있습니다.

왜 '지식'이 아니라 '믿음'일까요? 세상의 모든 것을 완벽하게 알 수 있는 에이전트는 없기 때문입니다. 현실 세계에서 작동하는 에이전트는 불확실성 속에서 판단해야 합니다.

**2. Desire: 이루고 싶은 것**
에이전트가 달성하고 싶은 목표, 선호, 가치입니다. 욕구는 서로 충돌할 수 있습니다. '건강해지고 싶다'와 '케이크 먹고 싶다'처럼요. 모든 욕구를 동시에 충족할 수 없기에, 에이전트는 선택해야 합니다.

**3. Intention: 실행하기로 마음먹은 것**
욕구 중에서 실제로 추구하기로 '결심'한 것이 의도입니다. 브랫먼에 따르면, 의도의 핵심은 '헌신(commitment)'입니다. 일단 의도를 품으면 쉽게 바꾸지 않고 추구합니다.

왜 이런 구분이 필요할까요? 매 순간 모든 가능성을 다시 계산하면 아무것도 못 합니다. 의도는 일종의 '자기 구속'으로, 생각의 폭을 좁혀 실제 행동을 가능케 합니다.

BDI 모델은 단순한 설계 패턴이 아닙니다. 이 모델은 "에이전트가 진짜 '생각'하는가?"라는 철학적 질문을 건드립니다.
흥미로운 점은 BDI가 인간의 마음을 모델로 삼았다는 것입니다. 우리도 세상에 대한 믿음을 갖고, 여러 욕구 사이에서 갈등하며, 결국 하나의 의도를 선택해 행동합니다. BDI 에이전트는 이 구조를 그대로 흉내 냅니다.
그렇다면 질문이 생깁니다. 믿음, 욕구, 의도를 가진 에이전트는 정말로 '마음'을 가진 걸까요? 아니면 마음이 있는 '척'하는 걸까요? 그리고 그 둘의 차이는 무엇일까요?
BDI 모델은 답을 주지 않습니다. 하지만 이 질문을 구체적으로 던질 수 있게 해줍니다. 

# Part 2: 실용적 정의

> 이제 LLM 시대에 에이전트가 어떻게 재정의되고 있는지 살펴봅니다. 학문적 정의와 비교하면서, 실제로 우리가 만들고 사용하는 에이전트를 이해해봅시다.

---

## LLM 시대, 무엇이 달라졌나

앞서 살펴본 정의들—러셀과 노빅의 최대 정의, 프랭클린과 그래서의 자율 에이전트, 울드리지와 제닝스의 지능적 에이전트, 그리고 BDI 모델—은 모두 LLM 이전에 등장했습니다. 그렇다면 LLM 시대의 에이전트는 이 정의들과 어떻게 연결될까요?

2022년, ReAct 논문이 발표되었습니다. 제목은 "ReAct: Synergizing Reasoning and Acting in Language Models", 즉 '추론과 행동의 시너지'였습니다.

핵심 아이디어는 간단합니다. LLM이 '생각'과 '행동'을 번갈아 하게 만드는 것입니다:

![ReAct 패턴](/pages-book-agent101/assets/react-pattern.svg)

이 사이클을 반복합니다. 단순해 보이지만, 이것이 LLM '에이전트'의 출발점이 되었습니다.

---

### 학문적 정의와의 비교

ReAct 에이전트를 울드리지-제닝스의 네 조건에 대입해봅시다:

| 조건 | ReAct 에이전트 |
|---|---|
| 자율성 | △ 루프 안에서는 자율적이지만, 인간이 시작해야 함 |
| 사회적 능력 | △ 도구와 상호작용하지만, 다른 에이전트와 협상하진 않음 |
| 반응성 | ✓ 관찰 결과에 따라 계획 수정 가능 |
| 능동성 | ✓ 목표를 향해 주도적으로 행동 |

BDI 관점에서도 흥미롭습니다. ReAct의 'Thought'는 Belief를 업데이트하는 과정이고, 'Action'은 Intention을 실행하는 과정입니다. 다만 Desire—무엇을 원하는가—는 여전히 인간이 프롬프트로 주입합니다.

결론적으로, LLM 에이전트는 '부분적' 에이전트입니다. 학문적 정의를 완전히 충족하진 않지만, 핵심 요소들을 갖추고 있습니다.

---

### 그럼 뭐가 진짜 새로운 걸까?

LLM이 가져온 진짜 혁신은 '범용성'입니다.

기존 에이전트들은 특정 도메인에 특화되어 있었습니다. 체스 두는 에이전트, 로봇 팔 제어 에이전트, 주식 거래 에이전트처럼요. 각각의 에이전트는 그 도메인에 맞게 Belief, Desire, Intention을 하드코딩해야 했습니다.

LLM은 언어를 통해 거의 모든 도메인에 대응할 수 있습니다. 특별한 재프로그래밍 없이도요. "이메일을 정리해줘"와 "코드를 리팩토링해줘"에 같은 에이전트가 대응할 수 있습니다. 이것이 '에이전트'라는 개념이 갑자기 대중적으로 주목받게 된 이유입니다.

---

## 에이전트가 아닌 것들

이제 반대로, '에이전트'라고 불리지만 실제로는 에이전트가 아닌 것들을 살펴봅시다. 앞서 정의한 기준들을 적용해보면 구분이 명확해집니다.

### RAG는 에이전트인가?

RAG(Retrieval-Augmented Generation)는 질문이 들어오면 관련 문서를 검색하고, 그 정보를 바탕으로 답변을 생성합니다.

에이전트일까요? 아닙니다.

프랭클린과 그래서의 정의를 떠올려보세요. 자율 에이전트는 '시간에 걸쳐' 자신의 목표를 추구해야 합니다. RAG는 단일 요청-응답 패턴입니다. 질문이 들어오면 답하고 끝입니다. 자신의 목표도 없고, 지속적 존재도 아닙니다. 정보 검색 도구이지, 에이전트가 아닙니다.

### 프롬프트 체이닝은?

여러 LLM 호출을 순차적으로 연결하는 것입니다. 예를 들어: 요약 → 번역 → 감정 분석.

이것도 에이전트가 아닙니다. 울드리지-제닝스의 '반응성'을 생각해보세요. 에이전트는 환경 변화에 따라 행동을 조정해야 합니다. 프롬프트 체이닝은 단계가 미리 정해져 있고, 결과에 따라 경로를 바꾸지 않습니다. 공장 조립 라인이 에이전트가 아닌 것처럼, 이것도 그냥 파이프라인입니다.

### 함수 호출(Function Calling)은?

LLM이 외부 함수를 호출하는 것입니다. 날씨 API를 부르거나, 계산기를 쓰거나.

이것 자체는 에이전트가 아닙니다. '능동성'을 떠올려보세요. 에이전트는 스스로 목표를 향해 행동을 개시해야 합니다. 함수 호출은 단순히 '도구를 쓸 수 있는 능력'일 뿐입니다. 망치를 가졌다고 목수가 되는 건 아니듯, 도구를 쓸 수 있다고 에이전트가 되는 건 아닙니다.

---

## 에이전트를 스펙트럼으로 바라보기

러셀과 노빅의 말을 다시 떠올려봅시다:

> "에이전트라는 개념은 시스템을 분석하기 위한 도구이지, 세상을 에이전트와 비에이전트로 나누는 절대적 구분이 아니다."

이 관점이 실용적입니다. "이건 에이전트다/아니다"라는 이분법 대신, "얼마나 에이전트적인가"라는 스펙트럼으로 보는 거죠.

![에이전트 스펙트럼](/pages-book-agent101/assets/agent-spectrum.svg)

### 스펙트럼의 다섯 단계

**레벨 0: 단순 호출**
사용자가 질문하면 LLM이 답변합니다. 한 번의 요청, 한 번의 응답. ChatGPT의 가장 기본적인 사용 방식입니다. 에이전트적 요소는 거의 없습니다.

**레벨 1: 도구 사용**
LLM이 외부 도구를 호출할 수 있습니다. 계산기, 검색, API 등. 하지만 언제 어떤 도구를 쓸지는 단일 턴 안에서 결정됩니다. Function Calling이 여기에 해당합니다. 자율성의 씨앗이 보이기 시작합니다.

**레벨 2: 반복적 추론**
LLM이 여러 단계에 걸쳐 생각하고 행동합니다. ReAct 패턴이 대표적입니다. 관찰 결과에 따라 다음 행동을 조정할 수 있습니다. 울드리지-제닝스의 '반응성'과 '능동성'이 나타납니다. 하지만 전체 과정은 하나의 세션 안에서 끝납니다.

**레벨 3: 지속적 에이전트**
세션을 넘어 상태를 유지합니다. 메모리가 있고, 이전 상호작용을 기억하며, 장기적 목표를 향해 점진적으로 진행합니다. 프랭클린과 그래서가 말한 '시간에 걸친 존재'가 실현됩니다. 하지만 여전히 인간의 트리거가 필요합니다.

**레벨 4: 자율 에이전트**
스스로 작동을 시작하고, 환경을 모니터링하며, 필요할 때 행동합니다. 인간은 감독자 역할만 합니다. BDI 모델의 이상에 가장 가까운 형태입니다. 현재 기술로는 제한된 도메인에서만 가능합니다.

---

### 실무적 함의

이 스펙트럼이 왜 유용할까요?

**과대평가를 막아줍니다.** "에이전트를 도입했다"고 할 때, 레벨 1인지 레벨 3인지에 따라 기대치가 완전히 달라져야 합니다. 레벨 1을 레벨 4처럼 포장하는 마케팅에 속지 않을 수 있습니다.

**설계 방향을 잡아줍니다.** 모든 문제에 레벨 4가 필요한 건 아닙니다. 단순한 문제에는 레벨 1이면 충분하고, 오히려 더 안정적입니다. 레벨이 올라갈수록 복잡성과 실패 가능성도 함께 올라갑니다.

**점진적 발전 경로를 보여줍니다.** 처음부터 완전 자율 에이전트를 만들려고 하면 실패합니다. 레벨 1에서 시작해서, 필요에 따라 레벨을 올려가는 게 현실적인 접근입니다.

---

### 마무리

결국 에이전트는 목적지가 아니라 방향입니다.

1995년 러셀과 노빅이 던진 질문, 1996년 프랭클린과 그래서가 제시한 자율성, 울드리지와 제닝스의 네 가지 조건, 그리고 BDI 모델의 마음 구조—이 모든 개념들이 30년이 지난 지금, LLM이라는 새로운 도구와 만나 다시 살아나고 있습니다.

우리가 만드는 시스템이 이 스펙트럼 위 어디에 있는지, 그리고 어디로 나아가야 하는지를 판단하는 프레임으로 활용하시면 됩니다. 중요한 건 라벨이 아니라, 우리가 풀려는 문제에 맞는 적절한 수준의 자율성을 선택하는 것입니다.

---
<!-- LLM Context Anchor -->
**핵심 요약**: 에이전트의 학문적 정의(러셀&노빅의 최대정의, 울드리지-제닝스 4조건: 자율성/사회적능력/반응성/능동성, BDI 모델: 믿음/욕구/의도)부터 LLM 시대 ReAct까지. 에이전트는 "있다/없다" 이분법이 아니라 "얼마나 에이전틱한가" 스펙트럼(레벨 0~4)으로 바라보기. RAG, 프롬프트 체이닝, 함수 호출 자체는 에이전트가 아님.

**키워드**: `울드리지-제닝스` `BDI모델` `ReAct` `에이전트스펙트럼` `자율성` `반응성` `능동성`
